{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda5ee77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17584/3183405200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'std_scaler'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m\"cat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_attribs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m ]).fit_transform(housing)\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[0mforest_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing_prepared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhousing_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[0mfeature_importances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Hands On ML exercises and practice\\Part 1 - Fundamentals of ML\\Chapter 2\\E2E Project\\env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;31m# set n_features_in_ attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Hands On ML exercises and practice\\Part 1 - Fundamentals of ML\\Chapter 2\\E2E Project\\env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_validate_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;31m# validate names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from six.moves import urllib\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ CONSTANT DATA SOURCE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\")\n",
    "MODEL_PATH = os.path.join(\"models\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PIPELINES AND FUNCTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "def load_housing_data():    \n",
    "    if not os.path.isdir(HOUSING_PATH):\n",
    "        os.makedirs(HOUSING_PATH)\n",
    "    tgz_path = os.path.join(HOUSING_PATH, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(HOUSING_URL, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(HOUSING_PATH)\n",
    "    housing_tgz.close()\n",
    "    csv_path = os.path.join(HOUSING_PATH, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "    \n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "        \n",
    "def choose_top_functions(arr,k):\n",
    "    k = min(k,len(np.array(arr)))\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class RemoveUnnecessaryFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, feature_importance, k = 5 ):\n",
    "        self.feature_importance = feature_importance\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_ind = choose_top_functions(self.feature_importance,self.k)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:,self.feature_ind]\n",
    "    \n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PROCESSING AND MODELLING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], bins = [0.,1.5,3.0,4.5,6,np.inf],labels=[1,2,3,4,5])\n",
    "stratfold = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in stratfold.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "for set_ in (strat_train_set, strat_test_set, housing):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)    \n",
    "    \n",
    "housing = strat_train_set.drop(\"median_house_value\",axis = 1)\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "svm_reg = joblib.load(MODEL_PATH+\"\\SVMRegressorBest.pkl\")\n",
    "forest_reg = joblib.load(MODEL_PATH+\"\\RandomForestRegressorBest.pkl\")\n",
    "\n",
    "housing_prepared = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "]).fit_transform(housing)\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "feature_importances = forest_reg.feature_importances_\n",
    "\n",
    "transform_and_fit = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ('choose_top',RemoveUnnecessaryFeatures(feature_importances,6)),\n",
    "    ('svm_reg_fit',svm_reg)\n",
    "])\n",
    "\n",
    "transform_and_fit.fit(housing,housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a8bd73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
